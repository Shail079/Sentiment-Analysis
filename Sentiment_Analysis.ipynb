{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2_Part_B.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis:**\n",
        "\n",
        "The process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer’s attitude towards a particular topic, product, etc. is positive, negative, or neutral. In common ML words its just a classification problem.\n"
      ],
      "metadata": {
        "id": "Q16psvveUxJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing useful packages**\n",
        "\n",
        "Lets first import all libraries. Please make sure that you have these libraries installed."
      ],
      "metadata": {
        "id": "hMraAZBnVpJ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzGSIh7Qrb_Q",
        "outputId": "1a410429-1008-44e1-ae75-4c5d6f03395d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "%matplotlib inline\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**\n",
        "\n",
        "\n",
        "*   Reading the data\n",
        "*   keeping only neccessary columns\n",
        "\n"
      ],
      "metadata": {
        "id": "9Z_xvTn7V2ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('data.csv')\n",
        "data = data[['text','sentiment']]"
      ],
      "metadata": {
        "id": "H0E478qBrlE1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2SRuvLXrrvm8",
        "outputId": "e8074a78-018b-4cbf-ad72-53ec8b68c26b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text sentiment\n",
              "0  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
              "1  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
              "2  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
              "3  RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
              "4  RT @warriorwoman91: I liked her and was happy ...  Negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c9c0348-b6a7-4bd2-bd61-96129540d408\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c9c0348-b6a7-4bd2-bd61-96129540d408')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c9c0348-b6a7-4bd2-bd61-96129540d408 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c9c0348-b6a7-4bd2-bd61-96129540d408');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Class Balance\n",
        "print('Class Split')\n",
        "print(data['sentiment'].value_counts())\n",
        "data['sentiment'].value_counts().plot.bar(figsize=(6,4),title='Classes Split for Dataset')\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "OUyA4earYKNj",
        "outputId": "49b99f6e-0a5c-41d6-dbaf-9ed6e57471e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Split\n",
            "Negative    8493\n",
            "Positive    2236\n",
            "Name: sentiment, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lets pre-process the data so that we can use it to train the model**\n",
        "\n",
        "\n",
        "*   Tokenize\n",
        "*   Padding (to make all sequence of same lengths)\n",
        "*   Converting sentiments into numerical data(One-hot form)\n",
        "*   train test split\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r9a8KRhpWnH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#declaring the maximum features for tokenizer\n",
        "max_fatures = 2000\n",
        "#creating word tokens\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "#padding the sequence of tokens\n",
        "X = pad_sequences(X)\n",
        "#converting sentiments to numerical form\n",
        "Y = pd.get_dummies(data['sentiment']).values\n",
        "#splitting training and testing data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19CeCI51sAsk",
        "outputId": "8dd4eb59-2b28-43ce-a9e3-b9d269a964d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8583, 29) (8583, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining model**\n",
        "\n",
        "Next, I compose the LSTM Network. Note that embed_dim, lstm_out, batch_size, droupout_x variables are hyper parameters, their values are somehow intuitive, can be and must be played with in order to achieve good results. Please also note that I am using softmax as activation function. The reason is that our Network is using categorical crossentropy, and softmax is just the right activation method for that."
      ],
      "metadata": {
        "id": "2L9uDGvPX6pI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#declaring embedding dimension\n",
        "embed_dim = 128\n",
        "#declaring LSTM units\n",
        "lstm_out = 196\n",
        "#define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "#model summary\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkJOUQ4GsFWL",
        "outputId": "d09c22e3-4cf6-4969-d59b-5722a077c9fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 29, 128)           256000    \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 29, 128)          0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 196)               254800    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 394       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 511,194\n",
            "Trainable params: 511,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **train and save first model**\n",
        "\n",
        "Here we train the Network. We should run much more than 15 epoch, but I would have to wait forever (run it later), so it is 15 for now."
      ],
      "metadata": {
        "id": "a14GRld-YIPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#training model\n",
        "batch_size = 128\n",
        "model.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upFB9klxsIRJ",
        "outputId": "250004a4-10c3-4cd3-bf1d-81df0cc06dc6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "68/68 [==============================] - 32s 419ms/step - loss: 0.4935 - accuracy: 0.7910\n",
            "Epoch 2/15\n",
            "68/68 [==============================] - 28s 411ms/step - loss: 0.3393 - accuracy: 0.8511\n",
            "Epoch 3/15\n",
            "68/68 [==============================] - 28s 405ms/step - loss: 0.2874 - accuracy: 0.8814\n",
            "Epoch 4/15\n",
            "68/68 [==============================] - 27s 397ms/step - loss: 0.2681 - accuracy: 0.8914\n",
            "Epoch 5/15\n",
            "68/68 [==============================] - 27s 395ms/step - loss: 0.2449 - accuracy: 0.8951\n",
            "Epoch 6/15\n",
            "68/68 [==============================] - 29s 424ms/step - loss: 0.2346 - accuracy: 0.9032\n",
            "Epoch 7/15\n",
            "68/68 [==============================] - 27s 400ms/step - loss: 0.2184 - accuracy: 0.9087\n",
            "Epoch 8/15\n",
            "68/68 [==============================] - 27s 397ms/step - loss: 0.2023 - accuracy: 0.9136\n",
            "Epoch 9/15\n",
            "68/68 [==============================] - 27s 395ms/step - loss: 0.1924 - accuracy: 0.9198\n",
            "Epoch 10/15\n",
            "68/68 [==============================] - 28s 414ms/step - loss: 0.1810 - accuracy: 0.9274\n",
            "Epoch 11/15\n",
            "68/68 [==============================] - 27s 397ms/step - loss: 0.1687 - accuracy: 0.9302\n",
            "Epoch 12/15\n",
            "68/68 [==============================] - 27s 400ms/step - loss: 0.1591 - accuracy: 0.9331\n",
            "Epoch 13/15\n",
            "68/68 [==============================] - 27s 403ms/step - loss: 0.1640 - accuracy: 0.9311\n",
            "Epoch 14/15\n",
            "68/68 [==============================] - 27s 402ms/step - loss: 0.1477 - accuracy: 0.9396\n",
            "Epoch 15/15\n",
            "68/68 [==============================] - 28s 405ms/step - loss: 0.1358 - accuracy: 0.9441\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f57e14d2550>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving our first model\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "OIdHmtdYKR4e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating the model**"
      ],
      "metadata": {
        "id": "nkgrNJlbYW5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluating the model by sentiments value\n",
        "predict_x = model.predict(X_test,batch_size = batch_size)\n",
        "Y_pred = np.argmax(predict_x,axis=1)\n",
        "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
        "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
        "\n",
        "#print classification report\n",
        "report = classification_report(df_test.true, df_test.pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9-ncSHjsNWD",
        "outputId": "eaac3664-0832-4f0b-cd6f-4d1596de7e3e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90      1713\n",
            "           1       0.59      0.58      0.59       433\n",
            "\n",
            "    accuracy                           0.84      2146\n",
            "   macro avg       0.74      0.74      0.74      2146\n",
            "weighted avg       0.83      0.84      0.84      2146\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear that finding negative tweets (class 0) goes very well (recall 0.90) for the Network but deciding whether is positive (class 1) is not really (recall 0.58). My educated guess here is that the positive training set is dramatically smaller than the negative, hence the “bad” results for positive tweets."
      ],
      "metadata": {
        "id": "7CYU1qPVYobW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Up-sample Minority Class**\n",
        "\n",
        "Up-sampling is the process of randomly duplicating observations from the minority class in order to reinforce its signal. There are several heuristics for doing so, but the most common way is to simply re-sample with replacement.\n",
        "\n",
        "It’s important that we separate test set before up-sampling because after up-sampling there will be multiple copies of same data point and if we do train test split after up-sampling the test set will not be completely unseen."
      ],
      "metadata": {
        "id": "a-AmeyWDYugz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate majority and minority classes\n",
        "data_majority = data[data['sentiment'] == 'Negative']\n",
        "data_minority = data[data['sentiment'] == 'Positive']\n",
        "\n",
        "# will be used later in defining class weights\n",
        "bias = data_minority.shape[0]/data_majority.shape[0]\n",
        "\n",
        "# lets split train/test data first then \n",
        "train = pd.concat([data_majority.sample(frac=0.8,random_state=200),\n",
        "         data_minority.sample(frac=0.8,random_state=200)])\n",
        "test = pd.concat([data_majority.drop(data_majority.sample(frac=0.8,random_state=200).index),\n",
        "        data_minority.drop(data_minority.sample(frac=0.8,random_state=200).index)])\n",
        "\n",
        "train = shuffle(train)\n",
        "test = shuffle(test)\n",
        "\n",
        "#print sentiment classification in train and test data\n",
        "print('positive data in training:',(train.sentiment == 'Positive').sum())\n",
        "print('negative data in training:',(train.sentiment == 'Negative').sum())\n",
        "print('positive data in test:',(test.sentiment == 'Positive').sum())\n",
        "print('negative data in test:',(test.sentiment == 'Negative').sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSIBkKCNv10v",
        "outputId": "28600621-8574-4d4a-80de-0d5d630539c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive data in training: 1789\n",
            "negative data in training: 6794\n",
            "positive data in test: 447\n",
            "negative data in test: 1699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate majority and minority classes in training data for up sampling \n",
        "data_majority = train[train['sentiment'] == 'Negative']\n",
        "data_minority = train[train['sentiment'] == 'Positive']\n",
        "\n",
        "print(\"majority class before upsample:\",data_majority.shape)\n",
        "print(\"minority class before upsample:\",data_minority.shape)\n",
        "\n",
        "# Upsample minority class\n",
        "data_minority_upsampled = resample(data_minority, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples= data_majority.shape[0],    # to match majority class\n",
        "                                 random_state=123) # reproducible results\n",
        " \n",
        "# Combine majority class with upsampled minority class\n",
        "data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
        " \n",
        "# Display new class counts\n",
        "print(\"After upsampling\\n\",data_upsampled.sentiment.value_counts(),sep = \"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciPS4SeHv4Td",
        "outputId": "b211a91f-c30b-4cf0-ab92-8018ee8f2bef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "majority class before upsample: (6794, 2)\n",
            "minority class before upsample: (1789, 2)\n",
            "After upsampling\n",
            "Negative    6794\n",
            "Positive    6794\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Repeating the Preprocessing steps after Up-sampling**"
      ],
      "metadata": {
        "id": "XFsSopFOZAhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training with whole data\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values) \n",
        "\n",
        "#tokenizing whole unsampled data\n",
        "X_train = tokenizer.texts_to_sequences(data_upsampled['text'].values)\n",
        "X_train = pad_sequences(X_train,maxlen=29)\n",
        "Y_train = pd.get_dummies(data_upsampled['sentiment']).values\n",
        "print('x_train shape:',X_train.shape)\n",
        "\n",
        "#padding the whole upsampled data\n",
        "X_test = tokenizer.texts_to_sequences(test['text'].values)\n",
        "X_test = pad_sequences(X_test,maxlen=29)\n",
        "Y_test = pd.get_dummies(test['sentiment']).values\n",
        "print(\"x_test shape\", X_test.shape)\n",
        "\n",
        "# creating final LSTM model\n",
        "embed_dim = 128\n",
        "lstm_out = 192\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X_train.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.4, recurrent_dropout=0.4))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "\n",
        "#summary of Final model\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j7h-SKUwftO",
        "outputId": "5db3b4a7-f89d-4174-c1e8-9d829eef13e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (13588, 29)\n",
            "x_test shape (2146, 29)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 29, 128)           256000    \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 29, 128)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 192)               246528    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 386       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 502,914\n",
            "Trainable params: 502,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training final model\n",
        "batch_size = 128\n",
        "model.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, verbose = 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YkbiGYswker",
        "outputId": "d6e5f096-b0af-4013-91b0-4ee7723b1076"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "107/107 [==============================] - 45s 368ms/step - loss: 0.5153 - accuracy: 0.7376\n",
            "Epoch 2/15\n",
            "107/107 [==============================] - 39s 368ms/step - loss: 0.3481 - accuracy: 0.8491\n",
            "Epoch 3/15\n",
            "107/107 [==============================] - 41s 381ms/step - loss: 0.3002 - accuracy: 0.8739\n",
            "Epoch 4/15\n",
            "107/107 [==============================] - 40s 369ms/step - loss: 0.2617 - accuracy: 0.8936\n",
            "Epoch 5/15\n",
            "107/107 [==============================] - 39s 362ms/step - loss: 0.2416 - accuracy: 0.9001\n",
            "Epoch 6/15\n",
            "107/107 [==============================] - 40s 372ms/step - loss: 0.2126 - accuracy: 0.9174\n",
            "Epoch 7/15\n",
            "107/107 [==============================] - 38s 359ms/step - loss: 0.1962 - accuracy: 0.9227\n",
            "Epoch 8/15\n",
            "107/107 [==============================] - 40s 370ms/step - loss: 0.1856 - accuracy: 0.9277\n",
            "Epoch 9/15\n",
            "107/107 [==============================] - 39s 360ms/step - loss: 0.1728 - accuracy: 0.9329\n",
            "Epoch 10/15\n",
            "107/107 [==============================] - 39s 362ms/step - loss: 0.1682 - accuracy: 0.9338\n",
            "Epoch 11/15\n",
            "107/107 [==============================] - 39s 361ms/step - loss: 0.1526 - accuracy: 0.9413\n",
            "Epoch 12/15\n",
            "107/107 [==============================] - 39s 364ms/step - loss: 0.1464 - accuracy: 0.9425\n",
            "Epoch 13/15\n",
            "107/107 [==============================] - 39s 368ms/step - loss: 0.1388 - accuracy: 0.9472\n",
            "Epoch 14/15\n",
            "107/107 [==============================] - 40s 370ms/step - loss: 0.1377 - accuracy: 0.9471\n",
            "Epoch 15/15\n",
            "107/107 [==============================] - 40s 372ms/step - loss: 0.1303 - accuracy: 0.9499\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f57dd04fd90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving final model\n",
        "model.save('final_model.h5')"
      ],
      "metadata": {
        "id": "ksymXd7bNdG3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Model Evaluation**"
      ],
      "metadata": {
        "id": "ahm2UkonZoPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating final model after upsampling the minority sentiment\n",
        "predict_x = model.predict(X_test,batch_size = batch_size)\n",
        "Y_pred = np.argmax(predict_x,axis=1)\n",
        "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
        "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
        "\n",
        "#print classification report\n",
        "print(classification_report(df_test.true, df_test.pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji7AoIVLylp7",
        "outputId": "75c41a76-1c6c-4f43-afd3-53dc4682cf70"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88      1699\n",
            "           1       0.55      0.65      0.59       447\n",
            "\n",
            "    accuracy                           0.81      2146\n",
            "   macro avg       0.72      0.75      0.74      2146\n",
            "weighted avg       0.83      0.81      0.82      2146\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Upsampling of positive sentiment, it is clear that finding negative tweets (class 0) goes very well (recall 0.86) for the Network and positive (class 1) also increases slightly after upsampling(recall 0.65)."
      ],
      "metadata": {
        "id": "wzgWzWeFxptQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the accuracy of final model\n",
        "print('Testing...')\n",
        "score, acc = model.evaluate(X_test, Y_test, batch_size=128)\n",
        "\n",
        "print('Validation Loss:', score)\n",
        "print('Test accuracy:', acc)\n",
        "\n",
        "print(\"Accuracy: {0:.2%}\".format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yte1lpz6Sqb",
        "outputId": "92bc8f13-0059-40bf-9129-26f5101fab3b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing...\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 0.6638 - accuracy: 0.8141\n",
            "Validation Loss: 0.663760244846344\n",
            "Test accuracy: 0.8140726685523987\n",
            "Accuracy: 81.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing model on Two data points**"
      ],
      "metadata": {
        "id": "RyiZLwcebz5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_1 = ['You are bad.']\n",
        "test_2 = ['You are good']\n",
        "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
        "test_1 = tokenizer.texts_to_sequences(test_1)\n",
        "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
        "test_1 = pad_sequences(test_1, maxlen=29, dtype='int32', value=0)\n",
        "\n",
        "sentiment_1 = model.predict(test_1,batch_size=1,verbose = 2)[0]\n",
        "if(np.argmax(sentiment_1) == 0):\n",
        "    print(\"negative\")\n",
        "elif (np.argmax(sentiment_1) == 1):\n",
        "    print(\"positive\")\n",
        "\n",
        "test_2 = tokenizer.texts_to_sequences(test_2)\n",
        "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
        "test_2 = pad_sequences(test_2, maxlen=29, dtype='int32', value=0)\n",
        "\n",
        "sentiment_2 = model.predict(test_2,batch_size=1,verbose = 2)[0]\n",
        "if(np.argmax(sentiment_2) == 0):\n",
        "    print(\"negative\")\n",
        "elif (np.argmax(sentiment_2) == 1):\n",
        "    print(\"positive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgvxvQpwzA3y",
        "outputId": "1811c459-3b5a-42c5-cf53-5083051fb4fc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - 32ms/epoch - 32ms/step\n",
            "negative\n",
            "1/1 - 0s - 28ms/epoch - 28ms/step\n",
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion** \n",
        "Thus from the output it is clearly observable that the model is successfully predicting two testing data points.\n",
        "\n",
        "\n",
        "1.   **You are bad.** : negative\n",
        "2.   **You are good.** : positive \n",
        "\n",
        "Thus due to upsampling the minority sentiment i.e. positive the number of duplicate positive sentiment increases in data and we successfully getting the desired output. Also the accuracy of model increase.\n",
        "\n",
        "The **accuracy** of our final model is **81.41%**. \n",
        "\n",
        "**Recommendation**\n",
        "\n",
        "\n",
        "I tried to get idea from \"https://medium.com/analytics-vidhya/re-sampling-imbalanced-training-corpus-for-sentiment-analysis-c9dc97f9eae1\" for resampling of the imbalanced data.\n",
        "\n"
      ],
      "metadata": {
        "id": "pDdhWz2Qyf19"
      }
    }
  ]
}
